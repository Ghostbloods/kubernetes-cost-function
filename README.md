ğŸ› ï¸ Project Overview
Goal:
Build a system that monitors and optimizes Kubernetes workloads by automatically scaling down underutilized workloads based on real-time usage patterns.

How It Works:
1ï¸âƒ£ Monitor Kubernetes usage (CPU, memory, request counts) using Prometheus & Grafana.
2ï¸âƒ£ Publish usage alerts to Pub/Sub when thresholds are exceeded.
3ï¸âƒ£ Trigger Cloud Run Functions to take actions (e.g., scale workloads down).
4ï¸âƒ£ Use Terraform to provision infrastructure and GitHub Actions for automation.

ğŸš€ Step-by-Step Execution Plan
Phase 1: Infrastructure Setup with Terraform
ğŸ”¹ Set up Google Kubernetes Engine (GKE).
ğŸ”¹ Deploy Cloud Pub/Sub for event-driven alerts.
ğŸ”¹ Provision Cloud Run Functions for executing scaling actions.

Phase 2: Monitoring and Data Collection
ğŸ”¹ Deploy Prometheus & Grafana (via Helm) for real-time monitoring.
ğŸ”¹ Collect CPU, memory, and request metrics from workloads.
ğŸ”¹ Set threshold-based alerting using Prometheus rules.

Phase 3: Automating Cost Optimization
ğŸ”¹ Set up a Kubernetes Controller (Python/Go) that listens to Pub/Sub alerts.
ğŸ”¹ Reduce replica counts of workloads based on thresholds.
ğŸ”¹ Implement automatic re-scaling when needed.

Phase 4: CI/CD Pipeline with GitHub Actions
ğŸ”¹ Automate Terraform deployments.
ğŸ”¹ Automate Kubernetes manifests & Helm chart updates.
ğŸ”¹ Validate changes before deployment.

